{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 0. Setup",
   "id": "4bab6b536a3bbf30"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 0.1. Imports",
   "id": "7c710cb31efc22bf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T11:33:51.602237Z",
     "start_time": "2025-01-26T11:33:51.593230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from part import Part\n",
    "from graph import Graph\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from graph_loader import load_graphs\n",
    "from gensim.models import Word2Vec\n",
    "from typing import Set, List, Tuple"
   ],
   "id": "b88072654c65be9f",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 0.2. Hyperparameters",
   "id": "afc9709f816531d7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T11:33:53.151186Z",
     "start_time": "2025-01-26T11:33:53.136186Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# General: ----------------------------\n",
    "SEED = 3\n",
    "random.seed(SEED)\n",
    "example_graph = 0\n",
    "\n",
    "# Random Walks: -----------------------\n",
    "num_walks = 16\n",
    "walk_length = 8\n",
    "\n",
    "# Embedding model: --------------------\n",
    "embedding_vector_size=16    # Size of the embedding vector\n",
    "window=5                    # Context window size --> Wie viele Wörter außenherum werden beachtet? --> ca. 5, da Durchscnittliche größe der Graphen (Entscheidung von 2 auf 5 machte Unterschied)\n",
    "min_count=1                 # Minimum occurrences of a node in the walks to include it in the vocabulary\n",
    "sg=1                        # Use Skip-Gram (sg=1) instead of CBOW (sg=0)\n",
    "workers=4                   # Number of CPU threads to use\n",
    "embedding_model_epochs=10   # Number of training epochs\n",
    "\n",
    "# GCN model: --------------------------\n",
    "gcn_input_dim = embedding_vector_size\n",
    "gcn_hidden_dim = 32\n",
    "gcn_output_dim = 16\n",
    "gcn_learning_rate = 0.025\n",
    "gcn_epochs = 5\n",
    "\n",
    "# GAE model: --------------------------\n",
    "gae_input_dim = embedding_vector_size\n",
    "gae_hidden_dim = 32\n",
    "gae_latent_dim = 16\n",
    "gae_learning_rate = 0.01\n",
    "gae_epochs = 200\n",
    "batch_size = 32"
   ],
   "id": "e795ef594aee2df0",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1 Process Training Data",
   "id": "f84849ab31f720e4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1.1 Helper Functions",
   "id": "696147c6aa69831b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T11:09:55.756262Z",
     "start_time": "2025-01-26T11:09:55.744264Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_part_list(graph_tuple):\n",
    "    part_list = []\n",
    "    nodes = graph_tuple[1].get_nodes()\n",
    "    for node in nodes:\n",
    "        part_list.append((node.get_id(), node.get_part().get_part_id()))\n",
    "    return part_list"
   ],
   "id": "fcc31631b6e6226b",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T11:09:56.335170Z",
     "start_time": "2025-01-26T11:09:56.322170Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_edge_list(graph_tuple):\n",
    "    edge_set = set()\n",
    "    edges = graph_tuple[1].get_edges()\n",
    "    for node, connected_nodes in edges.items():\n",
    "        for connected_node in connected_nodes:\n",
    "\n",
    "            # Store edges by node_ID and part_ID + node_ID and part_ID or source and target\n",
    "            # Make sure each edge is only stored once (unidirectionally)\n",
    "            edge = tuple(sorted((\n",
    "                (node.get_id(), int(node.get_part().get_part_id())),\n",
    "                (connected_node.get_id(), int(connected_node.get_part().get_part_id()))\n",
    "            )))\n",
    "            edge_set.add(edge)\n",
    "\n",
    "    return list(edge_set)\n"
   ],
   "id": "3ddb61ccdd8eadc",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T11:09:56.850011Z",
     "start_time": "2025-01-26T11:09:56.838011Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def prepare_graph_data(graph_dataset):\n",
    "    part_list_dict = {}\n",
    "    edge_list_dict = {}\n",
    "\n",
    "    for index, graph in enumerate(graph_dataset):\n",
    "        part_list_dict[index] = create_part_list(graph)\n",
    "        edge_list_dict[index] = create_edge_list(graph)\n",
    "\n",
    "    # Sort the lists within the dictionaries\n",
    "    for key in part_list_dict.keys():\n",
    "        part_list_dict[key] = sorted(part_list_dict[key], key=lambda x: x[0])  # Sort by NodeID\n",
    "\n",
    "    for key in edge_list_dict.keys():\n",
    "        edge_list_dict[key] = sorted(edge_list_dict[key], key=lambda x: (x[0][0], x[1][0]))  # Sort edges by source and target\n",
    "\n",
    "    return part_list_dict, edge_list_dict\n",
    "\n"
   ],
   "id": "64f219cd7779c75e",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1.2 Prepare Datasets",
   "id": "8a1934e464d30ed2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.2.1 Graph Dataset",
   "id": "57732c10da5e591b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T11:10:01.051133Z",
     "start_time": "2025-01-26T11:10:01.034125Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GraphDataset(Dataset):\n",
    "    def __init__(self, file_path: str, train=False, validation=False, test=False, seed=42):\n",
    "        if not os.path.exists(file_path):\n",
    "            raise FileNotFoundError(f\"Dataset file not found at {file_path}\")\n",
    "\n",
    "        self.graphs = load_graphs(file_path)\n",
    "\n",
    "        if sum([train, validation, test]) != 1:\n",
    "            raise ValueError(\"Exactly one of 'train', 'validation', or 'test' must be True.\")\n",
    "\n",
    "        # Create global mapping for unique parts\n",
    "        self.family_part_dict = {}\n",
    "\n",
    "        unique_parts = set()\n",
    "        for graph in self.graphs:\n",
    "            parts = graph.get_parts()\n",
    "            for part in parts:\n",
    "                unique_parts.add(int(part.get_part_id()))\n",
    "                self.family_part_dict[int(part.get_part_id())] = int(part.get_family_id())\n",
    "\n",
    "        # unique parts and mapping across all graphs (not just within a certain split)\n",
    "        unique_parts = sorted(list(unique_parts))\n",
    "        self.total_global_part_to_idx = {part: idx for idx, part in enumerate(unique_parts)} # mapping part_id to index\n",
    "        self.idx_to_part_id = {idx: part for part, idx in self.total_global_part_to_idx.items()}  # Reverse mapping\n",
    "        self.total_num_unique_parts = len(unique_parts)\n",
    "\n",
    "        # Split: 70% training, 15% validation, 15% test\n",
    "        train_graphs, test_graphs = train_test_split(self.graphs, test_size=0.3, random_state=seed)\n",
    "        validation_graphs, test_graphs = train_test_split(test_graphs, test_size=0.5, random_state=seed)\n",
    "\n",
    "        if train:\n",
    "            self.graphs = train_graphs\n",
    "        elif validation:\n",
    "            self.graphs = validation_graphs\n",
    "        elif test:\n",
    "            self.graphs = test_graphs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.graphs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # return parts und graphen\n",
    "        graph = self.graphs[idx]\n",
    "\n",
    "        # Initialize a count vector for parts\n",
    "        part_frequency_vector = np.zeros(self.total_num_unique_parts, dtype=np.int32)\n",
    "\n",
    "        # Count occurrences of each part\n",
    "        parts = graph.get_parts()\n",
    "        for part in parts:\n",
    "            part_id = int(part.get_part_id())\n",
    "            mapped_id = self.total_global_part_to_idx[part_id]\n",
    "            part_frequency_vector[mapped_id] += 1  # Increment the count\n",
    "\n",
    "        return self.graphs[idx].get_parts(), self.graphs[idx]"
   ],
   "id": "b347c90f963a1263",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.2.2 Read Datasets",
   "id": "9f0a40c69e91c67c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T11:10:07.405417Z",
     "start_time": "2025-01-26T11:10:04.579792Z"
    }
   },
   "cell_type": "code",
   "source": [
    "training_set = GraphDataset(\"data/graphs.dat\", train = True, seed=SEED)\n",
    "validation_set = GraphDataset(\"data/graphs.dat\", validation = True, seed=SEED)\n",
    "testing_set = GraphDataset(\"data/graphs.dat\", test = True, seed=SEED)"
   ],
   "id": "dbf6a034ec7180fc",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.2.3 Prepare Part and Edge Data for all graphs",
   "id": "aea9df2049faee21"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T11:34:02.604028Z",
     "start_time": "2025-01-26T11:34:02.333977Z"
    }
   },
   "cell_type": "code",
   "source": "graph_parts_dict, graph_edge_dict = prepare_graph_data(training_set)",
   "id": "592cdad5bc1e4685",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1.3. Create Embeddings",
   "id": "aed3d4d9a579305d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Embeddings represent features of a node e.g. 16 features of Part 1 are 16 Embedding values",
   "id": "8fb1d77c07d8e7b8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.3.1. Random Walk Embeddings",
   "id": "4ffdeb350c8017a7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T11:34:06.658248Z",
     "start_time": "2025-01-26T11:34:06.650245Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_random_walks_single_graph(edges):\n",
    "\n",
    "    walks = []\n",
    "    graph = {}\n",
    "\n",
    "    # Build adjacency list\n",
    "    for edge in edges:\n",
    "        node1, node2 = edge[0][1], edge[1][1]  # Extract PartIDs\n",
    "        graph.setdefault(node1, []).append(node2)\n",
    "        graph.setdefault(node2, []).append(node1)\n",
    "\n",
    "    # Perform random walks\n",
    "    for _ in range(num_walks):\n",
    "        for node in graph.keys():\n",
    "            walk = [node]  # Start the walk with the current node\n",
    "            while len(walk) < walk_length:\n",
    "                cur = walk[-1]  # Get the last node in the walk\n",
    "                if cur in graph:\n",
    "                    walk.append(random.choice(graph[cur]))  # Add a random neighbor\n",
    "                else:\n",
    "                    break\n",
    "            walks.append(walk)  # Add the walk to the list of walks\n",
    "\n",
    "    return walks"
   ],
   "id": "9018a0ab0d4356a2",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T11:34:12.708326Z",
     "start_time": "2025-01-26T11:34:09.193971Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Generate Random Walks for all graphs:\n",
    "random_walks = {}\n",
    "for index, graph in enumerate(training_set):\n",
    "    random_walks[index] = generate_random_walks_single_graph(graph_edge_dict[index])"
   ],
   "id": "8977e9fe1162abf7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1334, 198, 1334, 83, 1334, 58, 1334, 58], [168, 1334, 83, 1334, 58, 1334, 198, 1334], [198, 1334, 83, 1334, 198, 1334, 58, 1334], [83, 1334, 168, 1334, 58, 1334, 83, 1334], [58, 1334, 83, 1334, 83, 1334, 58, 1334], [1334, 198, 1334, 168, 1334, 198, 1334, 198], [168, 1334, 83, 1334, 83, 1334, 58, 1334], [198, 1334, 58, 1334, 83, 1334, 83, 1334], [83, 1334, 58, 1334, 198, 1334, 83, 1334], [58, 1334, 83, 1334, 168, 1334, 168, 1334], [1334, 198, 1334, 83, 1334, 83, 1334, 168], [168, 1334, 83, 1334, 58, 1334, 58, 1334], [198, 1334, 83, 1334, 168, 1334, 58, 1334], [83, 1334, 83, 1334, 58, 1334, 198, 1334], [58, 1334, 83, 1334, 198, 1334, 83, 1334], [1334, 58, 1334, 58, 1334, 58, 1334, 83], [168, 1334, 83, 1334, 83, 1334, 58, 1334], [198, 1334, 83, 1334, 168, 1334, 58, 1334], [83, 1334, 83, 1334, 83, 1334, 58, 1334], [58, 1334, 168, 1334, 168, 1334, 83, 1334], [1334, 83, 1334, 198, 1334, 198, 1334, 83], [168, 1334, 83, 1334, 168, 1334, 58, 1334], [198, 1334, 58, 1334, 83, 1334, 83, 1334], [83, 1334, 168, 1334, 58, 1334, 83, 1334], [58, 1334, 198, 1334, 83, 1334, 58, 1334], [1334, 83, 1334, 168, 1334, 58, 1334, 83], [168, 1334, 83, 1334, 168, 1334, 58, 1334], [198, 1334, 83, 1334, 83, 1334, 83, 1334], [83, 1334, 58, 1334, 168, 1334, 198, 1334], [58, 1334, 83, 1334, 58, 1334, 168, 1334], [1334, 58, 1334, 58, 1334, 198, 1334, 58], [168, 1334, 168, 1334, 168, 1334, 58, 1334], [198, 1334, 58, 1334, 168, 1334, 168, 1334], [83, 1334, 198, 1334, 58, 1334, 168, 1334], [58, 1334, 198, 1334, 58, 1334, 168, 1334], [1334, 198, 1334, 168, 1334, 198, 1334, 83], [168, 1334, 168, 1334, 58, 1334, 168, 1334], [198, 1334, 83, 1334, 168, 1334, 83, 1334], [83, 1334, 198, 1334, 168, 1334, 168, 1334], [58, 1334, 168, 1334, 83, 1334, 83, 1334], [1334, 83, 1334, 83, 1334, 83, 1334, 198], [168, 1334, 83, 1334, 198, 1334, 83, 1334], [198, 1334, 168, 1334, 83, 1334, 168, 1334], [83, 1334, 83, 1334, 83, 1334, 83, 1334], [58, 1334, 198, 1334, 58, 1334, 58, 1334], [1334, 83, 1334, 83, 1334, 168, 1334, 83], [168, 1334, 168, 1334, 168, 1334, 168, 1334], [198, 1334, 58, 1334, 83, 1334, 198, 1334], [83, 1334, 58, 1334, 58, 1334, 83, 1334], [58, 1334, 83, 1334, 168, 1334, 83, 1334], [1334, 58, 1334, 168, 1334, 58, 1334, 168], [168, 1334, 58, 1334, 58, 1334, 58, 1334], [198, 1334, 198, 1334, 198, 1334, 58, 1334], [83, 1334, 83, 1334, 83, 1334, 168, 1334], [58, 1334, 83, 1334, 83, 1334, 198, 1334], [1334, 198, 1334, 168, 1334, 83, 1334, 58], [168, 1334, 198, 1334, 198, 1334, 58, 1334], [198, 1334, 58, 1334, 83, 1334, 198, 1334], [83, 1334, 83, 1334, 83, 1334, 198, 1334], [58, 1334, 83, 1334, 198, 1334, 83, 1334], [1334, 83, 1334, 83, 1334, 83, 1334, 83], [168, 1334, 198, 1334, 198, 1334, 198, 1334], [198, 1334, 198, 1334, 58, 1334, 83, 1334], [83, 1334, 83, 1334, 83, 1334, 168, 1334], [58, 1334, 83, 1334, 168, 1334, 83, 1334], [1334, 168, 1334, 83, 1334, 83, 1334, 83], [168, 1334, 198, 1334, 83, 1334, 58, 1334], [198, 1334, 83, 1334, 83, 1334, 83, 1334], [83, 1334, 58, 1334, 83, 1334, 83, 1334], [58, 1334, 83, 1334, 83, 1334, 168, 1334], [1334, 58, 1334, 198, 1334, 83, 1334, 168], [168, 1334, 58, 1334, 83, 1334, 58, 1334], [198, 1334, 83, 1334, 83, 1334, 168, 1334], [83, 1334, 58, 1334, 83, 1334, 83, 1334], [58, 1334, 168, 1334, 168, 1334, 58, 1334], [1334, 198, 1334, 83, 1334, 83, 1334, 83], [168, 1334, 168, 1334, 83, 1334, 168, 1334], [198, 1334, 198, 1334, 83, 1334, 58, 1334], [83, 1334, 198, 1334, 58, 1334, 198, 1334], [58, 1334, 83, 1334, 83, 1334, 83, 1334]]\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.3.2. Train Word2Vec Model with Random Walk Embeddings",
   "id": "56e90dd52409156c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T11:34:26.456868Z",
     "start_time": "2025-01-26T11:34:14.580479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Flattening the random walks to be able to train Embedding model on them:\n",
    "flat_random_walks = [walk for walks in random_walks.values() for walk in walks]\n",
    "\n",
    "# Training embedding model:\n",
    "word2vec_model = Word2Vec(\n",
    "    sentences=flat_random_walks,\n",
    "    vector_size=embedding_vector_size,\n",
    "    window=window,\n",
    "    min_count=min_count,\n",
    "    sg=sg,\n",
    "    workers=workers,\n",
    "    epochs=embedding_model_epochs\n",
    ")\n",
    "word2vec_model.save(\"parts_embeddings.model\")\n",
    "print(\"Embedding model saved \\n\")"
   ],
   "id": "4ff26036d3c3d1a9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding model saved \n",
      "\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1.4. Prepare Training Data",
   "id": "9b8b0f960ac1edcd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T11:30:55.633388Z",
     "start_time": "2025-01-26T11:30:54.048524Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create one parts-torch, one edge-torch and one label-torch for each graph:\n",
    "all_graph_data = []\n",
    "\n",
    "for graph_id in graph_parts_dict.keys():\n",
    "\n",
    "    # Retrieve parts and edges for the current graph\n",
    "    graph_parts = graph_parts_dict[graph_id]\n",
    "    graph_edges = graph_edge_dict[graph_id]\n",
    "\n",
    "    # 1. Extract Parts Features:\n",
    "    parts_list = []\n",
    "    for part in graph_parts:\n",
    "        embedding = word2vec_model.wv[int(part[1])]\n",
    "        parts_list.append(embedding)\n",
    "    parts = torch.tensor(parts_list, dtype=torch.float)\n",
    "\n",
    "    # 2. Extract Positive Edges:\n",
    "    edge_index_list = []\n",
    "    for edge in graph_edges:\n",
    "        source_node = edge[0][0]\n",
    "        target_node = edge[1][0]\n",
    "        edge_index_list.append((source_node, target_node))\n",
    "    edge_index = torch.tensor(edge_index_list, dtype=torch.long).t().contiguous()\n",
    "\n",
    "    # 3. Extract Negative Edges:\n",
    "    num_nodes = len(graph_parts)\n",
    "    all_edges = torch.combinations(torch.arange(num_nodes), r=2).T  # All possible edges\n",
    "    all_edges = all_edges.to(edge_index.device)  # Ensure device compatibility\n",
    "\n",
    "    # Identify negative edges\n",
    "    neg_edge_mask = ~torch.any(\n",
    "        (all_edges.unsqueeze(-1) == edge_index.unsqueeze(1)).all(dim=0), dim=1\n",
    "    )\n",
    "    neg_edge_index = all_edges[:, neg_edge_mask]\n",
    "\n",
    "    # 4. Create Edge Labels:\n",
    "    pos_edge_label = torch.ones(edge_index.size(1))  # Label 1 for positive edges\n",
    "    neg_edge_label = torch.zeros(neg_edge_index.size(1))  # Label 0 for negative edges\n",
    "\n",
    "    # Combine positive and negative edges:\n",
    "    edge_index = torch.cat([edge_index, neg_edge_index], dim=1)\n",
    "    edge_label = torch.cat([pos_edge_label, neg_edge_label], dim=0)\n",
    "\n",
    "    # 5. Create Data Object for the Current Graph:\n",
    "    single_graph_data = Data(\n",
    "        x=parts,\n",
    "        edge_index=edge_index,\n",
    "        edge_label=edge_label  # Store labels for training\n",
    "    )\n",
    "    all_graph_data.append(single_graph_data)"
   ],
   "id": "ca6ef2b2511423f1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pasca\\AppData\\Local\\Temp\\ipykernel_14428\\58172175.py:15: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:281.)\n",
      "  parts = torch.tensor(parts_list, dtype=torch.float)\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3. Setup GCN",
   "id": "21caf4da72ab57aa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.1 Define GCN\n",
   "id": "c23475c512cb9d2c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T12:07:08.259397Z",
     "start_time": "2025-01-26T12:07:08.226432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GCN_Graph_Predictor(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN_Graph_Predictor, self).__init__()\n",
    "        self.conv1 = GCNConv(gcn_input_dim, gcn_hidden_dim)\n",
    "        self.conv2 = GCNConv(gcn_hidden_dim, gcn_output_dim)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # print(\"Input to Conv1:\", x)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        # print(\"Output of Conv1:\", x)\n",
    "        x = F.relu(x)\n",
    "        # print(\"After ReLU:\", x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        # print(\"Output of Conv2:\", x)\n",
    "        return x\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        \"\"\"\n",
    "        Initializes weights of the GCNConv layers using Xavier initialization\n",
    "        and biases to zero.\n",
    "        \"\"\"\n",
    "        for layer in self.modules():\n",
    "            if isinstance(layer, GCNConv):\n",
    "                torch.nn.init.xavier_uniform_(layer.lin.weight)  # Xavier initialization for weights\n",
    "                if layer.lin.bias is not None:\n",
    "                    torch.nn.init.zeros_(layer.lin.bias)  # Zero initialization for biases\n",
    "\n",
    "    def train_model(self, data, optimizer):\n",
    "\n",
    "        self.train()\n",
    "        all_losses = []\n",
    "\n",
    "        for epoch in range(gcn_epochs):\n",
    "            total_loss = 0\n",
    "\n",
    "            for i, graph_data in enumerate(data):\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Feed Forward:\n",
    "                predictions = self(graph_data.x, graph_data.edge_index)                 # Using self(...) in pytorch always triggers the forward pass\n",
    "\n",
    "                # Compute probabilistic adjacency matrix\n",
    "                adjacency_logits = torch.mm(predictions, predictions.t())\n",
    "                adjacency_probs = torch.sigmoid(adjacency_logits)\n",
    "                adjacency_probs = adjacency_probs.clamp(min=1e-7, max=1 - 1e-7)             # To prevent invalid log inputs, clip the values of adjacency_probs to a small positive range away from 0 and 1\n",
    "#                 if i == 1: print(\"Adjacency------------------ \\n\", adjacency_probs)\n",
    "\n",
    "                # Loss computation using precomputed edge labels\n",
    "                edge_probs = adjacency_probs[graph_data.edge_index[0], graph_data.edge_index[1]]\n",
    "                loss = F.binary_cross_entropy(edge_probs, graph_data.edge_label)\n",
    "\n",
    "                # Backpropagation\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            # Avg Loss for the epoche:\n",
    "            avg_loss = total_loss / len(data)\n",
    "            all_losses.append(avg_loss)\n",
    "            print(f\"Epoch {epoch + 1}/{gcn_epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        return all_losses\n",
    "\n",
    "    def predict_graph(self, parts: Set[Part]) -> Graph:\n",
    "        \"\"\"\n",
    "        Predicts a graph from the given set of parts.\n",
    "        :param parts: Set of Part objects.\n",
    "        :return: A predicted graph by the GCN\n",
    "        \"\"\"\n",
    "\n",
    "        family_id_mapping = {}\n",
    "        for part in parts:\n",
    "            family_id_mapping[part.get_part_id()] = part.get_family_id()\n",
    "\n",
    "        # Step 1: Sort and process parts\n",
    "        parts = list(sorted(parts, key=lambda p: int(p.get_part_id())))  # Sort by Part ID\n",
    "        part_ids = [int(p.get_part_id()) for p in parts]  # Extract Part IDs\n",
    "        print(\"Part IDs:\", part_ids)\n",
    "\n",
    "        # Step 2: Convert Part IDs to embeddings\n",
    "        part_embeddings = [word2vec_model.wv[part_id] for part_id in part_ids]\n",
    "        x = torch.tensor(part_embeddings, dtype=torch.float)\n",
    "\n",
    "        # Step 3: Create a Data object for querying\n",
    "        edge_index = torch.empty((2, 0), dtype=torch.long)  # No edges for initial query\n",
    "        query_data = Data(x=x, edge_index=edge_index)\n",
    "\n",
    "        # Step 4: Pass data through the GCN model\n",
    "        node_embeddings = self(query_data.x, query_data.edge_index)  # Forward pass\n",
    "        adjacency_logits = torch.mm(node_embeddings, node_embeddings.t())\n",
    "        adjacency_probs = torch.sigmoid(adjacency_logits)\n",
    "\n",
    "        # Step 5: Generate adjacency matrix and edges\n",
    "        threshold = 0.5  # Define threshold for edge prediction\n",
    "        adjacency_matrix = (adjacency_probs > threshold).float()\n",
    "\n",
    "        # Extract predicted edges\n",
    "        edges = torch.nonzero(adjacency_matrix, as_tuple=False).t()\n",
    "        edge_list = [(int(src), int(dst)) for src, dst in zip(edges[0], edges[1])]\n",
    "\n",
    "        return self.create_mst(family_id_mapping, edge_list, parts)\n",
    "\n",
    "    def create_mst(\n",
    "        edge_list: List[Tuple[int, int]],\n",
    "        parts: List[Part],\n",
    "    ) -> Graph:\n",
    "        \"\"\"\n",
    "        Creates a minimum spanning tree (MST) using the adjacency matrix and part IDs.\n",
    "        \"\"\"\n",
    "        # Step 1: Create a NetworkX graph from adjacency matrix\n",
    "        building_graph = Graph()\n",
    "\n",
    "        building_parts_list = {}\n",
    "        for part in parts:\n",
    "            print(part)\n",
    "\n",
    "        for edge in edge_list:\n",
    "            source_index = edge[0]\n",
    "            target_index = edge[1]\n",
    "            building_graph.add_undirected_edge(parts[source_index], parts[target_index])\n",
    "\n",
    "        building_graph.draw()\n",
    "\n",
    "        return building_graph\n"
   ],
   "id": "66d0a8c9764dcc6c",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.2 Initialize GCN",
   "id": "fcd7d743ae842574"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T12:07:10.386560Z",
     "start_time": "2025-01-26T12:07:10.346498Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gcn_model = GCN_Graph_Predictor()\n",
    "gcn_model.initialize_weights()\n",
    "optimizer = torch.optim.Adam(gcn_model.parameters(), lr=gcn_learning_rate)"
   ],
   "id": "77829a917627fa05",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3.3 Train GCN",
   "id": "3d7dd900734e35d0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T12:07:17.927383Z",
     "start_time": "2025-01-26T12:07:13.245978Z"
    }
   },
   "cell_type": "code",
   "source": "gcn_model.train_model(all_graph_data, optimizer)",
   "id": "a3fe7122daa8a6ea",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[27], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mgcn_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mall_graph_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[25], line 40\u001B[0m, in \u001B[0;36mGCN_Graph_Predictor.train_model\u001B[1;34m(self, data, optimizer)\u001B[0m\n\u001B[0;32m     37\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m     39\u001B[0m \u001B[38;5;66;03m# Feed Forward:\u001B[39;00m\n\u001B[1;32m---> 40\u001B[0m predictions \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mgraph_data\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgraph_data\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43medge_index\u001B[49m\u001B[43m)\u001B[49m                 \u001B[38;5;66;03m# Using self(...) in pytorch always triggers the forward pass\u001B[39;00m\n\u001B[0;32m     42\u001B[0m \u001B[38;5;66;03m# Compute probabilistic adjacency matrix\u001B[39;00m\n\u001B[0;32m     43\u001B[0m adjacency_logits \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmm(predictions, predictions\u001B[38;5;241m.\u001B[39mt())\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ai-project\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ai-project\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[25], line 9\u001B[0m, in \u001B[0;36mGCN_Graph_Predictor.forward\u001B[1;34m(self, x, edge_index)\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, edge_index):\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;66;03m# print(\"Input to Conv1:\", x)\u001B[39;00m\n\u001B[1;32m----> 9\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     10\u001B[0m     \u001B[38;5;66;03m# print(\"Output of Conv1:\", x)\u001B[39;00m\n\u001B[0;32m     11\u001B[0m     x \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mrelu(x)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ai-project\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ai-project\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ai-project\\lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py:266\u001B[0m, in \u001B[0;36mGCNConv.forward\u001B[1;34m(self, x, edge_index, edge_weight)\u001B[0m\n\u001B[0;32m    263\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpropagate(edge_index, x\u001B[38;5;241m=\u001B[39mx, edge_weight\u001B[38;5;241m=\u001B[39medge_weight)\n\u001B[0;32m    265\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 266\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[43mout\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\n\u001B[0;32m    268\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 27
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
