{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-22T14:55:35.480961Z",
     "start_time": "2025-01-22T14:55:35.464733Z"
    }
   },
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import gensim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv, GAE\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from torch.utils.data import Dataset\n",
    "from graph_loader import load_graphs\n",
    "from gensim.models import Word2Vec"
   ],
   "outputs": [],
   "execution_count": 93
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Hyperparameters",
   "id": "eb72fc5a4113134b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T14:55:37.230271Z",
     "start_time": "2025-01-22T14:55:37.215271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "SEED = 0\n",
    "random.seed(SEED)\n",
    "\n",
    "# Embedding creation:\n",
    "num_walks = 20\n",
    "walk_length = 20\n",
    "\n",
    "# Embedding model:\n",
    "embedding_vector_size=64      # Size of the embedding vector\n",
    "window=2            # Context window size --> Wie viele Wörter außenherum werden beachtet?\n",
    "min_count=1         # Minimum frequency for a node to be included\n",
    "sg=1                # Use Skip-Gram (sg=1) instead of CBOW (sg=0)\n",
    "workers=4           # Number of CPU threads to use\n",
    "epochs=10           # Number of training epochs\n",
    "\n",
    "# GNN model:\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Training:\n",
    "num_epochs = 10\n"
   ],
   "id": "9c0c32faf5116ba4",
   "outputs": [],
   "execution_count": 94
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T14:55:38.310382Z",
     "start_time": "2025-01-22T14:55:38.300864Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "\n",
    "    graph.get_edges()\n",
    "\n",
    "    Edge:\n",
    "        node: Aktuelle Node\n",
    "        connected_nodes: List an Nodes, von node\n",
    "\n",
    "        E.g.: edges.get_items() liefer alle edges:\n",
    "        node: Node\n",
    "        connected_nodes: [Dict(Nodes)]\n",
    "        Verbindung Node 2 zu Node 0:\n",
    "            Node(NodeID=2, Part=Part(PartID=58, FamilyID=31))\n",
    "            [Node(NodeID=0, Part=Part(PartID=1621, FamilyID=0))]\n",
    "\n",
    "        Verbindung Node 0 zu Nodes 1, 2, 3, 4, 5:\n",
    "            Node(NodeID=0, Part=Part(PartID=1621, FamilyID=0)),\n",
    "            [Node(NodeID=1, Part=Part(PartID=58, FamilyID=31)), Node(NodeID=2, Part=Part(PartID=58, FamilyID=31)), Node(NodeID=3, Part=Part(PartID=58, FamilyID=31)), Node(NodeID=4, Part=Part(PartID=58, FamilyID=31))]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ],
   "id": "115ae08f3895c06b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n    graph.get_edges()\\n\\n    Edge:\\n        node: Aktuelle Node\\n        connected_nodes: List an Nodes, von node\\n\\n        E.g.: edges.get_items() liefer alle edges:\\n        node: Node\\n        connected_nodes: [Dict(Nodes)]\\n        Verbindung Node 2 zu Node 0:\\n            Node(NodeID=2, Part=Part(PartID=58, FamilyID=31))\\n            [Node(NodeID=0, Part=Part(PartID=1621, FamilyID=0))]\\n\\n        Verbindung Node 0 zu Nodes 1, 2, 3, 4, 5:\\n            Node(NodeID=0, Part=Part(PartID=1621, FamilyID=0)),\\n            [Node(NodeID=1, Part=Part(PartID=58, FamilyID=31)), Node(NodeID=2, Part=Part(PartID=58, FamilyID=31)), Node(NodeID=3, Part=Part(PartID=58, FamilyID=31)), Node(NodeID=4, Part=Part(PartID=58, FamilyID=31))]\\n\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T15:11:57.750589Z",
     "start_time": "2025-01-22T15:11:57.736632Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_edge_list(graph):\n",
    "    edge_set = set()\n",
    "    edges = graph.get_edges()\n",
    "    for node, connected_nodes in edges.items():\n",
    "        for connected_node in connected_nodes:\n",
    "\n",
    "            # Store edges by node_ID and part_ID + node_ID and part_ID or source and target\n",
    "            # Make sure each edge is only stored once (unidirectionally)\n",
    "            edge = tuple(sorted((\n",
    "                (node.get_id(), int(node.get_part().get_part_id())),\n",
    "                (connected_node.get_id(), int(connected_node.get_part().get_part_id()))\n",
    "            )))\n",
    "            edge_set.add(edge)\n",
    "\n",
    "    return list(edge_set)\n"
   ],
   "id": "88cd87c292cc50ad",
   "outputs": [],
   "execution_count": 124
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T15:08:47.785985Z",
     "start_time": "2025-01-22T15:08:47.769986Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_part_list(graph):\n",
    "    part_list = []\n",
    "    nodes = graph.get_nodes()\n",
    "    for node in nodes:\n",
    "        part_list.append((node.get_id(), node.get_part().get_part_id()))\n",
    "    return part_list"
   ],
   "id": "fe5b6bb4eda112d2",
   "outputs": [],
   "execution_count": 117
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T15:08:49.562528Z",
     "start_time": "2025-01-22T15:08:49.544526Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GraphDataset(Dataset):\n",
    "    def __init__(self, file_path: str, train=False, validation=False, test=False, seed=42):\n",
    "        if not os.path.exists(file_path):\n",
    "            raise FileNotFoundError(f\"Dataset file not found at {file_path}\")\n",
    "\n",
    "        self.graphs = load_graphs(file_path)\n",
    "\n",
    "        if sum([train, validation, test]) != 1:\n",
    "            raise ValueError(\"Exactly one of 'train', 'validation', or 'test' must be True.\")\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        graph = self.graphs[idx]\n",
    "        return graph"
   ],
   "id": "7d02531e2b730e2a",
   "outputs": [],
   "execution_count": 118
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T15:08:52.034813Z",
     "start_time": "2025-01-22T15:08:52.022300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def prepare_graph_data(graph_dataset):\n",
    "    edge_list_dict = {}\n",
    "    part_list_dict = {}\n",
    "\n",
    "    for index, graph in enumerate(graph_dataset):\n",
    "        edge_list_dict[index] =  create_edge_list(graph)\n",
    "        part_list_dict[index] = create_part_list(graph)\n",
    "\n",
    "    return edge_list_dict, part_list_dict\n"
   ],
   "id": "be6984d789bbf691",
   "outputs": [],
   "execution_count": 119
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T15:08:55.741403Z",
     "start_time": "2025-01-22T15:08:54.409951Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#training_set = GraphDataset(\"data/graphs.dat\", train = True, seed=SEED)\n",
    "#validation_set = GraphDataset(\"data/graphs.dat\", validation = True, seed=SEED)\n",
    "testing_set = GraphDataset(\"data/graphs.dat\", test = True, seed=SEED)"
   ],
   "id": "48484cc9f557f6bd",
   "outputs": [],
   "execution_count": 120
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T15:12:03.511640Z",
     "start_time": "2025-01-22T15:12:03.246273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "edge_list, parts_list = prepare_graph_data(testing_set)\n",
    "print(len(edge_list), len(parts_list))\n",
    "print(edge_list[0])\n",
    "print(parts_list[0])"
   ],
   "id": "352cc1f5a8f2777c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11159 11159\n",
      "[((0, 1621), (2, 58)), ((0, 1621), (3, 58)), ((0, 1621), (1, 58)), ((0, 1621), (4, 58))]\n",
      "[(4, 58), (0, 1621), (2, 58), (3, 58), (1, 58)]\n"
     ]
    }
   ],
   "execution_count": 125
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2. Embeddings",
   "id": "1384aa8479432362"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.1. Generating Random Walks",
   "id": "34a765f7beae4e8c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T14:55:56.923160Z",
     "start_time": "2025-01-22T14:55:56.906160Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_random_walks_single_graph(edges, num_walks=10, walk_length=5):\n",
    "    \"\"\"\n",
    "    Generate random walks for a single graph.\n",
    "\n",
    "    Parameters:\n",
    "        edges (list): Edge list for a single graph.\n",
    "        num_walks (int): Number of random walks to generate per node.\n",
    "        walk_length (int): Length of each random walk.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of random walks, where each walk is a list of PartIDs.\n",
    "    \"\"\"\n",
    "    # TODO in das ReadMe: Hier fraglich of random-walks funktionieren, da viel hin und her wegen non-cyclical\n",
    "    # TODO Maximilian: Context\n",
    "\n",
    "\n",
    "    walks = []\n",
    "    graph = {}\n",
    "    # Build adjacency list\n",
    "    for edge in edges:\n",
    "        node1, node2 = edge[0][1], edge[1][1]  # Extract PartIDs\n",
    "        graph.setdefault(node1, []).append(node2)\n",
    "        graph.setdefault(node2, []).append(node1)\n",
    "\n",
    "    # Perform random walks\n",
    "    for _ in range(num_walks):\n",
    "        for node in graph.keys():\n",
    "            walk = [node]  # Start the walk with the current node\n",
    "            while len(walk) < walk_length:\n",
    "                cur = walk[-1]  # Get the last node in the walk\n",
    "                if cur in graph:\n",
    "                    walk.append(random.choice(graph[cur]))  # Add a random neighbor\n",
    "                else:\n",
    "                    break\n",
    "            walks.append(walk)  # Add the walk to the list of walks\n",
    "\n",
    "    return walks"
   ],
   "id": "6d466be4bdc00283",
   "outputs": [],
   "execution_count": 103
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T14:56:11.673215Z",
     "start_time": "2025-01-22T14:56:00.043286Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Generate Random Walks for all graphs:\n",
    "\"\"\"\n",
    "    execution Dauer: ca. 12 Sekunden\n",
    "\"\"\"\n",
    "\n",
    "random_walks = {}\n",
    "for index, graph in enumerate(testing_set):\n",
    "    random_walks[index] = generate_random_walks_single_graph(edge_list[index], num_walks=num_walks, walk_length=walk_length)\n",
    "print(random_walks[0])"
   ],
   "id": "7c095ab94b97e21c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58'], ['58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621'], ['1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58'], ['58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621'], ['1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58'], ['58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621'], ['1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58'], ['58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621'], ['1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58'], ['58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621'], ['1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58'], ['58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621'], ['1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58'], ['58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621'], ['1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58'], ['58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621'], ['1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58'], ['58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621'], ['1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58'], ['58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621'], ['1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58'], ['58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621'], ['1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58'], ['58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621'], ['1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58'], ['58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621'], ['1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58'], ['58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621'], ['1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58'], ['58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621'], ['1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58'], ['58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621'], ['1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58'], ['58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621'], ['1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58'], ['58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621'], ['1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58'], ['58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621'], ['1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58'], ['58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621']]\n"
     ]
    }
   ],
   "execution_count": 104
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.2. Training Embeddings\n",
   "id": "a068614d7b5eb95b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T14:56:24.342656Z",
     "start_time": "2025-01-22T14:56:23.815704Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "    flattening Dauer: instant\n",
    "    training Dauer:\n",
    "\"\"\"\n",
    "flat_random_walks = [walk for walks in random_walks.values() for walk in walks]         # flat_random_walks Länge: 131.0240\n",
    "\n",
    "print(len(flat_random_walks))\n",
    "\n",
    "# Use only the first 100 random walks\n",
    "limited_walks = flat_random_walks[:10000]\n",
    "\n",
    "print(\"Walks flattened\")\n",
    "print(flat_random_walks[:10])\n",
    "word2vec_model = Word2Vec(\n",
    "    sentences=limited_walks,    # The random walks\n",
    "    vector_size=embedding_vector_size,    # Size of the embedding vector\n",
    "    window=window,              # Context window size\n",
    "    min_count=min_count,        # Minimum frequency for a node to be included\n",
    "    sg=sg,                      # Use Skip-Gram (sg=1) instead of CBOW (sg=0)\n",
    "    workers=workers,            # Number of CPU threads to use\n",
    "    epochs=epochs               # Number of training epochs\n",
    ")\n",
    "word2vec_model.save(\"node_embeddings.model\")"
   ],
   "id": "99465e8272d4f967",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1310240\n",
      "Walks flattened\n",
      "[['1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58'], ['58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621'], ['1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58'], ['58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621'], ['1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58'], ['58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621'], ['1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58'], ['58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621'], ['1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58'], ['58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621', '58', '1621']]\n"
     ]
    }
   ],
   "execution_count": 105
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T14:25:21.604266Z",
     "start_time": "2025-01-22T14:25:21.548026Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get the embedding for a specific node (e.g., '10')\n",
    "embedding = word2vec_model.wv['1000']\n",
    "print(\"Embedding for node 58:\", embedding)"
   ],
   "id": "96c1ca642c5e5cbc",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key '1000' not present\"",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[65], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Get the embedding for a specific node (e.g., '10')\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m embedding \u001B[38;5;241m=\u001B[39m \u001B[43mword2vec_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwv\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m1000\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEmbedding for node 58:\u001B[39m\u001B[38;5;124m\"\u001B[39m, embedding)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ai-project\\lib\\site-packages\\gensim\\models\\keyedvectors.py:403\u001B[0m, in \u001B[0;36mKeyedVectors.__getitem__\u001B[1;34m(self, key_or_keys)\u001B[0m\n\u001B[0;32m    389\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Get vector representation of `key_or_keys`.\u001B[39;00m\n\u001B[0;32m    390\u001B[0m \n\u001B[0;32m    391\u001B[0m \u001B[38;5;124;03mParameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    400\u001B[0m \n\u001B[0;32m    401\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    402\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key_or_keys, _KEY_TYPES):\n\u001B[1;32m--> 403\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_vector\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey_or_keys\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    405\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m vstack([\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_vector(key) \u001B[38;5;28;01mfor\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m key_or_keys])\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ai-project\\lib\\site-packages\\gensim\\models\\keyedvectors.py:446\u001B[0m, in \u001B[0;36mKeyedVectors.get_vector\u001B[1;34m(self, key, norm)\u001B[0m\n\u001B[0;32m    422\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_vector\u001B[39m(\u001B[38;5;28mself\u001B[39m, key, norm\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m    423\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Get the key's vector, as a 1D numpy array.\u001B[39;00m\n\u001B[0;32m    424\u001B[0m \n\u001B[0;32m    425\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    444\u001B[0m \n\u001B[0;32m    445\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 446\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_index\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    447\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m norm:\n\u001B[0;32m    448\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfill_norms()\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ai-project\\lib\\site-packages\\gensim\\models\\keyedvectors.py:420\u001B[0m, in \u001B[0;36mKeyedVectors.get_index\u001B[1;34m(self, key, default)\u001B[0m\n\u001B[0;32m    418\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m default\n\u001B[0;32m    419\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 420\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mKey \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m not present\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mKeyError\u001B[0m: \"Key '1000' not present\""
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training Data Generation",
   "id": "deb1b0540f29282"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T15:12:18.062338Z",
     "start_time": "2025-01-22T15:12:17.982784Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. Prepare Node Features:\n",
    "\n",
    "# Convert the list of embeddings to a NumPy array first\n",
    "node_features_array = np.array([word2vec_model.wv[str(node_id)] for node_id in word2vec_model.wv.index_to_key])\n",
    "\n",
    "# Convert the NumPy array to a PyTorch tensor\n",
    "node_features = torch.tensor(node_features_array, dtype=torch.float)\n",
    "\n",
    "print(\"------------------------------------------------------------------\")\n",
    "print(\"Node Features (node_features):\")\n",
    "print(node_features)  # Prints the tensor values\n",
    "print(\"Shape:\", node_features.shape)  # Prints the shape of the tensor\n",
    "\n",
    "\"\"\"\n",
    "    print(node_features.shape)\n",
    "\n",
    "    Output: node_features.shape:\n",
    "    e.g. torch.Size([221, 64]):\n",
    "        - 221 Vocabulary in embedding dictionary: 221 PartIDs\n",
    "        - 64 dimensionality: 64 floating point embedding\n",
    "\"\"\"\n",
    "\n",
    "# 2. Prepare Edge Index: Flatten your edge_list (from prepare_graph_data)\n",
    "edge_index_list = []\n",
    "for edges in edge_list.values():\n",
    "    for edge in edges:\n",
    "        edge_index_list.append([edge[0][1], edge[1][1]])  # Extract NodeIDs\n",
    "\n",
    "# Convert edge_index_list to tensor\n",
    "edge_index = torch.tensor(edge_index_list, dtype=torch.long).t().contiguous()\n",
    "\n",
    "print(\"------------------------------------------------------------------\")\n",
    "print(\"\\nEdge Index (edge_index):\")\n",
    "print(edge_index)  # Prints the tensor values\n",
    "print(\"Shape:\", edge_index.shape)  # Prints the shape of the tensor\n",
    "# Optional: Print a few edges for inspection\n",
    "print(\"\\nSample edges:\")\n",
    "for i in range(min(10, edge_index.size(1))):  # Print the first 10 edges or fewer\n",
    "    print(f\"Edge {i}: Source Node = {edge_index[0, i].item()}, Target Node = {edge_index[1, i].item()}\")\n",
    "\n",
    "\"\"\"\n",
    "    print(edge_index.shape)\n",
    "\n",
    "    Output: edge_index.shape:\n",
    "    e.g. torch.Size([2, 73981])\n",
    "        - 2 Rows: Source and Target Nodes\n",
    "        - 73981 columns: 73981 edges between source and target nodes\n",
    "        edge_list = torch.tensor([\n",
    "            [0, 1, 2],  # Source nodes\n",
    "            [1, 2, 3]   # Target nodes\n",
    "        ])\n",
    "\"\"\"\n",
    "\n",
    "# 3. Edge Labels:\n",
    "# Positive edges\n",
    "pos_edge_index = edge_index\n",
    "pos_edge_label = torch.ones(pos_edge_index.size(1))  # Labels = 1 for positive edges\n",
    "\n",
    "# Negative edges\n",
    "neg_edge_index = negative_sampling(\n",
    "    edge_index=edge_index,\n",
    "    num_nodes=node_features.size(0),\n",
    "    num_neg_samples=pos_edge_index.size(1)  # Same number as positive edges\n",
    ")\n",
    "neg_edge_label = torch.zeros(neg_edge_index.size(1))  # Labels = 0 for negative edges\n",
    "\n",
    "# Combine positive and negative edges\n",
    "edge_label_index = torch.cat([pos_edge_index, neg_edge_index], dim=1)\n",
    "edge_label = torch.cat([pos_edge_label, neg_edge_label], dim=0)\n",
    "\n",
    "print(\"------------------------------------------------------------------\")\n",
    "print(\"\\nPositive Edges (pos_edge_index):\")\n",
    "print(pos_edge_index)  # Prints the positive edge tensor\n",
    "print(\"Shape:\", pos_edge_index.shape)\n",
    "\n",
    "print(\"\\nPositive Edge Labels (pos_edge_label):\")\n",
    "print(pos_edge_label)  # Prints labels for positive edges\n",
    "print(\"Shape:\", pos_edge_label.shape)\n",
    "\n",
    "\n",
    "print(\"------------------------------------------------------------------\")\n",
    "print(\"\\nNegative Edges (neg_edge_index):\")\n",
    "print(neg_edge_index)  # Prints the negative edge tensor\n",
    "print(\"Shape:\", neg_edge_index.shape)\n",
    "\n",
    "print(\"\\nNegative Edge Labels (neg_edge_label):\")\n",
    "print(neg_edge_label)  # Prints labels for negative edges\n",
    "print(\"Shape:\", neg_edge_label.shape)"
   ],
   "id": "a4fa3e3c8032cc7a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "Node Features (node_features):\n",
      "tensor([[-0.1659, -0.2757, -0.1877,  ..., -0.3490, -0.3277, -0.5999],\n",
      "        [ 0.2603, -0.2521, -0.7242,  ..., -0.3345,  0.1911,  0.8414],\n",
      "        [ 0.1541, -0.3777, -0.9810,  ..., -0.7086, -0.4216,  0.2896],\n",
      "        ...,\n",
      "        [ 0.5048, -0.1711,  0.9390,  ..., -0.9987,  0.0703,  0.0722],\n",
      "        [ 0.4811, -0.7730,  0.0211,  ..., -0.8020, -0.7575, -0.9186],\n",
      "        [ 0.2690, -0.6496,  0.3211,  ...,  0.1330, -1.0856, -0.1125]])\n",
      "Shape: torch.Size([221, 64])\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Edge Index (edge_index):\n",
      "tensor([[1621, 1621, 1621,  ...,  587,  587,  587],\n",
      "        [  58,   58,   58,  ...,   61,   11,   25]])\n",
      "Shape: torch.Size([2, 73981])\n",
      "\n",
      "Sample edges:\n",
      "Edge 0: Source Node = 1621, Target Node = 58\n",
      "Edge 1: Source Node = 1621, Target Node = 58\n",
      "Edge 2: Source Node = 1621, Target Node = 58\n",
      "Edge 3: Source Node = 1621, Target Node = 58\n",
      "Edge 4: Source Node = 1507, Target Node = 370\n",
      "Edge 5: Source Node = 1507, Target Node = 9\n",
      "Edge 6: Source Node = 1507, Target Node = 83\n",
      "Edge 7: Source Node = 1507, Target Node = 83\n",
      "Edge 8: Source Node = 1507, Target Node = 155\n",
      "Edge 9: Source Node = 1507, Target Node = 370\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Positive Edges (pos_edge_index):\n",
      "tensor([[1621, 1621, 1621,  ...,  587,  587,  587],\n",
      "        [  58,   58,   58,  ...,   61,   11,   25]])\n",
      "Shape: torch.Size([2, 73981])\n",
      "\n",
      "Positive Edge Labels (pos_edge_label):\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.])\n",
      "Shape: torch.Size([73981])\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Negative Edges (neg_edge_index):\n",
      "tensor([], size=(2, 0), dtype=torch.int64)\n",
      "Shape: torch.Size([2, 0])\n",
      "\n",
      "Negative Edge Labels (neg_edge_label):\n",
      "tensor([])\n",
      "Shape: torch.Size([0])\n"
     ]
    }
   ],
   "execution_count": 126
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model: Graph Neural Network",
   "id": "10415195a755d01a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T14:56:37.280982Z",
     "start_time": "2025-01-22T14:56:37.265984Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LinkPredictionGNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(LinkPredictionGNN, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # GNN layers\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "    def decode(self, z, edge_label_index):\n",
    "        # Compute edge scores\n",
    "        source_embeddings = z[edge_label_index[0]]  # Embeddings of source nodes\n",
    "        target_embeddings = z[edge_label_index[1]]  # Embeddings of target nodes\n",
    "        edge_scores = (source_embeddings * target_embeddings).sum(dim=-1)  # Dot product\n",
    "        return edge_scores\n",
    "\n"
   ],
   "id": "4641636383ab13a3",
   "outputs": [],
   "execution_count": 107
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Model Initialization",
   "id": "57b13f7b699b2639"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T14:56:39.729987Z",
     "start_time": "2025-01-22T14:56:39.716984Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Model parameters:\n",
    "input_dim = node_features.size(1)   # Embedding dimension from Word2Vec\n",
    "hidden_dim = embedding_vector_size\n",
    "\n",
    "# Initialize GNN:\n",
    "model = LinkPredictionGNN(input_dim, hidden_dim)\n",
    "\n",
    "# Optimizer and loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()    # Binary cross-entropy with logits\n"
   ],
   "id": "b2531e179a0ed5ab",
   "outputs": [],
   "execution_count": 108
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training Loop",
   "id": "d9292fba7696cd0b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T14:56:44.994267Z",
     "start_time": "2025-01-22T14:56:43.920885Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass: Generate node embeddings\n",
    "    z = model(node_features, edge_index)\n",
    "\n",
    "    # Decode edges: Predict scores for edges\n",
    "    edge_scores = model.decode(z, edge_label_index)\n",
    "\n",
    "    # Compute loss\n",
    "    loss = criterion(edge_scores, edge_label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}\")\n"
   ],
   "id": "16dab5c792e00ef1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.0000\n",
      "Epoch 2/10, Loss: 0.0000\n",
      "Epoch 3/10, Loss: 0.0000\n",
      "Epoch 4/10, Loss: 0.0000\n",
      "Epoch 5/10, Loss: 0.0000\n",
      "Epoch 6/10, Loss: 0.0000\n",
      "Epoch 7/10, Loss: 0.0000\n",
      "Epoch 8/10, Loss: 0.0000\n",
      "Epoch 9/10, Loss: 0.0000\n",
      "Epoch 10/10, Loss: 0.0000\n"
     ]
    }
   ],
   "execution_count": 109
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Model Evaluation\n",
   "id": "ace8d867e8af7b7e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T14:56:50.069977Z",
     "start_time": "2025-01-22T14:56:50.032541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    z = model(node_features, edge_index)    # Node embeddings\n",
    "    edge_scores = model.decode(z, edge_label_index)  # Edge predictions\n",
    "\n",
    "    # Convert logits to probabilities\n",
    "    edge_probs = torch.sigmoid(edge_scores)\n",
    "\n",
    "    # Classify edges (threshold at 0.5)\n",
    "    predicted_labels = (edge_probs > 0.5).long()"
   ],
   "id": "1a748c889526b7b1",
   "outputs": [],
   "execution_count": 110
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Model Accuracy\n",
   "id": "adbd2f7e479a68f5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T14:56:52.621715Z",
     "start_time": "2025-01-22T14:56:52.616716Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate accuracy\n",
    "correct = (predicted_labels == edge_label).sum().item()\n",
    "accuracy = correct / edge_label.size(0)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ],
   "id": "e12feb181a538506",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000\n"
     ]
    }
   ],
   "execution_count": 111
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
